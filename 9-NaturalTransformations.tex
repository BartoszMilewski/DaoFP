\documentclass[DaoFP]{subfiles}
\begin{document}
\setcounter{chapter}{8}

\chapter{Natural Transformations}

We've seen that, when two objects $A$ and $B$ are isomorphic, they generate bijections between sets of arrows, which we can now express as isomorphisms between hom-sets:
\[\mathcal{C}(A, X) \cong \mathcal{C}(B, X)\]
\[\mathcal{C}(X, A) \cong \mathcal{C}(X, B)\]
The converse is not true, though. An isomorphism between hom-sets does not result in an isomorphism between object unless additional naturality conditions are satisfied. We'll now re-formulate these naturality conditions in progressively more general settings.

\section{Natural Transformations Between Hom-Functors}

One way an isomorphism between two objects can be established is by directly providing two arrows---one the inverse of the other. But quite often it's easier to do it indirectly, by defining bijections between arrows, either the ones impinging on the objects, or the ones emanating from the objects. 

For instance, as we've seen before, we may have an invertible mapping of arrows $\alpha_X$.
\[
 \begin{tikzcd}
 \node(x) at (0, 2) {X};
 \node(a) at (-2, 0) {A};
 \node(b) at (2, 0) {B};
 \node(c1) at (-1, 1.5) {};
 \node(c2) at (-1.5, 1) {};
 \node(c3) at (-1, 2) {};
 \node(c4) at (-2, 1) {};
 \node(d1) at (1, 1.5) {};
 \node(d2) at (1.5, 1) {};
 \node(d3) at (1, 2) {};
 \node(d4) at (2, 1) {};
\node (aa) at (-1, 0.75) {};
 \node (bb) at (1, 0.75) {};
 \draw[->] (x) .. controls (c1)  and (c2) .. (a); % bend
 \draw[->, green] (x) .. controls (c3)  and (c4) .. (a); % bend
 \draw[->, blue] (x) -- (a); 
  \draw[->] (x) .. controls (d1)  and (d2) .. (b); % bend
 \draw[->, green] (x) .. controls (d3)  and (d4) .. (b); % bend
 \draw[->, blue] (x) -- (b); 
 \draw[->, red, dashed] (aa) -- node[above]{\alpha_X} (bb);
 \end{tikzcd}
\]
In other words, for every $X$, there is a mapping of hom-sets:
\[ \alpha_X \colon \mathcal{C}(X, A) \to \mathcal{C}(X, B) \]
Since $X$ is arbitrary, we are effectively dealing with a mapping between two (contravariant) functors:  $\mathcal{C}(-, A)$ and $\mathcal{C}(-, B)$. 

The functor $\mathcal{C}(-, A)$ describes the way the worlds sees $A$, and the functor $\mathcal{C}(-, B)$ describes the way the world sees $B$. 

The transformation $\alpha$ switches back and forth between these two views. Every \emph{component} of $\alpha$, the bijection $\alpha_X$, shows that the view of $A$ from $X$ is isomorphic to the view of $B$ from $X$. 

The naturality condition we discussed before was the condition:

\[ \alpha_Y \circ (- \circ g) = (- \circ g) \circ \alpha_X \]
It relates components of $\alpha$ taken at different objects. In other words, it relates the views from two different observers $X$ and $Y$, who are connected by the arrow $g \colon Y \to X$. 

We can now see that both sides of this equation map hom-sets to hom-sets, more precisely:
\[\mathcal{C}(X, A) \to \mathcal{C}(Y, B)\]
Precomposition with $g \colon Y \to X$ is also a mapping of hom-sets. In fact it is the lifting of $g$ by the contravariant hom-functor. 

The naturality condition can therefore be rewritten as:
\[ \alpha_Y \circ \mathcal{C}(g, A) = \mathcal{C}(g, B) \circ \alpha_X \]
It can be illustrated by this commuting diagram:
\[
 \begin{tikzcd}
 \mathcal{C}(X, A)
 \arrow[d, "\alpha_X"]
 \arrow[r, "{\mathcal{C}(g, A)}"]
 &
 \mathcal{C}(Y, A)
  \arrow[d, "\alpha_Y"]
 \\
 \mathcal{C}(X, B)
 \arrow[r, "{\mathcal{C}(g, B)}"]
& \mathcal{C}(Y, B)
 \end{tikzcd}
\]

We can now say that  an invertible transformation $\alpha$ between the functors $\mathcal{C}(-, A)$ and $\mathcal{C}(-, B)$ that satisfies the naturality condition is equivalent to an isomorphism between $A$ and $B$.

We can follow exactly the same reasoning to translate the case of the outgoing arrows. This time we start with a transformation $\beta$ whose components are:
\[ \beta_X \colon \mathcal{C}(A, X) \to \mathcal{C}(B, X) \]
The two (covariant) functors $\mathcal{C}(A, -)$ and $\mathcal{C}(B, -)$ describe the view of the world from the perspective of $A$ and $B$, respectively. The invertible transformation $\beta$ tells us that these two views are equivalent, and the naturality condition 
\[ (g \circ -) \circ \beta_X = \beta_Y \circ (g \circ -) \]
tells us that they behave nicely when we switch focus.

Here's the commuting diagram illustrates the naturality condition:
\[
 \begin{tikzcd}
 \mathcal{C}(A, X)
 \arrow[d, "\beta_X"]
 \arrow[r, "{\mathcal{C}(A, g)}"]
 &
 \mathcal{C}(A, Y)
  \arrow[d, "\beta_Y"]
 \\
 \mathcal{C}(B, X)
 \arrow[r, "{\mathcal{C}(B, g)}"]
& \mathcal{C}(B, Y)
 \end{tikzcd}
\]

Again, such an invertible natural transformation $\beta$ establishes the isomorphism between $A$ and $B$.

\section{Natural Transformation Between Functors}

The two hom-functors from the previous section were
\[ F X =   \mathcal{C}(A, X)\]
\[ G X =   \mathcal{C}(B, X)\]
They both map the category $\mathcal{C}$ to  $\mathbf{Set}$, where the hom-sets live. We can say that they create two different \emph{models} of $\mathcal{C}$ inside $\mathbf{Set}$. 

A natural transformation is a structure-preserving mapping between models. 

This idea naturally extends to functors between any pair of categories. Any two functors
\[ F \colon \mathcal{C} \to \mathcal{D} \]
\[ G \colon \mathcal{C} \to \mathcal{D} \]
may be seen as two different models of $\mathcal{C}$ inside $\mathcal{D}$. 

To transform one model into another we connect the corresponding dots using arrows in $\mathcal{D}$. 

For every object $X$ in $\mathcal{C}$ we pick an arrow that goes from $F X$ to $G X$:
\[ \alpha_X \colon F X \to G X \]

However, the structure of the models is defined by arrows. For every arrow $f \colon X \to Y$ in $\mathcal{C}$, there are two corresponding arrows in $\mathcal{D}$:
\[ F f \colon F X \to F Y\]
\[ G f \colon G X \to G Y \]
These are the two liftings of $f$. You can use them to move within the bounds of each of the two models. And then there are the components of $\alpha$ which let you switch between the models. 

Naturality imposes the condition that it shouldn't matter whether you first move inside the first model and then jump to the second one, or first jump to the second model and then move within it. This is illustrated by the commuting \emph{naturality square}:

\[
 \begin{tikzcd}
 F X
 \arrow[d, "\alpha_X"]
 \arrow[r, "F f"]
 &
F Y
  \arrow[d, "\alpha_Y"]
 \\
G X
 \arrow[r, "G f"]
& G Y
 \end{tikzcd}
\]

A family of arrows $\alpha_X$ that satisfies the naturality condition is called a \emph{natural transformation}. 

If every component $\alpha_X$ of a natural transformation is an isomorphism, $\alpha$ is called a \emph{natural isomorphism}. 

We can now restate the main result about isomorphisms: Two objects are isomorphic if and only if there is a natural isomorphism between their hom-functors (either the covariant, or the contravariant ones).

Natural transformations provide a very convenient higher-order way of expressing commuting conditions in a variety of situations. We'll use them in this capacity to reformulate the definitions of algebraic data types.

\section{Natural Transformations in Programming}

A natural transformation is a family of arrows parameterized by objects. In programming, this corresponds to a family of functions parameterized by types, that is a \emph{polymorphic function}. 

The type of the argument to a natural transformation is constructed by one functor, and the return type by another. 

In Haskell, we can define a data type that accepts two type constructors representing two functors, and producing a new type of natural transformation:

\begin{haskell}
data Natural :: (Type -> Type) -> (Type -> Type) -> Type where
  Natural :: (forall a. f a -> g a) -> Natural f g
\end{haskell}
The \hask{forall} quantifier tells the compiler that the function is polymorphic---that is, it's defined for every type \hask{a}. As long as \hask{f} and \hask{g} are functors, this formula defines a natural transformation. 

The types defined by \hask{forall} are very special, though. The are polymorphic in the sense of \emph{parametric polymorphism}. It means that a single formula is used for all types. We've seen the example of the identity function, which can be written as:
\begin{haskell}
id :: forall a. a -> a
id x = x
\end{haskell}
The body of this function is very simple, just the variable \hask{x}. It doesn't matter what type \hask{x} is, the formula remains the same.

This is in contrast to \emph{ad-hoc polymorphism}. An ad-hoc polymorphic function may use different implementations for different types. An example of such a function is \hask{fmap}, the member function of the \hask{Functor} typeclass. There is one implementation of \hask{fmap} for lists, a different one for \hask{Maybe}, and so on, case by case. 

It turns out that limiting the type of a natural transformation to adhere to parametric polymorphism has far reaching consequences. Such a function automatically satisfies the naturality condition. This is an example of parametricity producing so called \emph{theorems for free}. 

The standard definition of a (parametric) natural transformation in Haskell uses a \emph{type synonym:}
\begin{haskell}
type Natural f g = forall a. f a -> g a
\end{haskell}
A \hask{type} declaration introduces an alias, a shorthand, for the right-hand-side.

Here's an example of a useful function that is a natural transformation between the list functor and the \hask{Maybe} functor:
\begin{haskell}
safeHead :: Natural [] Maybe
safeHead [] = Nothing
safeHead (a : as) = Just a
\end{haskell}
(The standard library \hask{head} function is ``unsafe'' in that it faults when given an empty list.)

A useful intuition for understanding natural transformations builds on the idea that functors acts like containers of data. There are two completely orthogonal things that you can do with a container: You can transform the data it contains, without changing the shape of the container. This is what \hask{fmap} does. Or you can transfer the data, without modifying it, to another container. This is what a natural transformation does: It's a procedure of moving ``stuff'' between containers with no way of knowing what kind of ``stuff'' it is. 

Naturality condition enforces the orthogonality of these two operations. It doesn't matter if you first modify the data and then move it to another container; or first move it, and then modify. 

This is another example of successfully decomposing a complex problem into a sequence of simpler ones. Keep in mind, though, that not every operation with containers of data can be decomposed in that way. Filtering, for instance, requires both examining the data, as well as changing the size or even the shape of the container. 

On the other hand, almost every parametrically polymorphic function is a natural transformation. In some cases you may have to consider the identity or the constant functor as either source or the target. For instance, the polymorphic identity function can be though of as a natural transformation between two identity functors.

\section{The Functor Category}

Objects and arrows are drawn differently. Objects are dots and arrows are pointy lines.

In the category of categories, $\mathbf{Cat}$, functors are drawn as arrows. But we have natural transformations that go between functors, so it looks like functors could be objects as well. 

What is an arrow in one category could be an object in another.

\subsection{Composition of natural transformations}

Natural transformations can only be defined between \emph{parallel} functors, that is functors that share the same source category and the same target category. Such parallel functors form a functor category. The standard notation for a functor category between two categories $\mathcal{C}$ and $\mathcal{D}$ is $[\mathcal{C}, \mathcal{D}]$, the two categories between square brackets.

The objects in $[\mathcal{C}, \mathcal{D}]$ are functors, the arrows are natural transformations. 

To show that this is indeed a category, we have to first define the composition of natural transformations. This is easy if you take into account that components of natural transformations are regular arrows in the target category. These arrows compose.

Indeed, suppose that we have a natural transformation $\alpha$ between two functors $F$ and $G$. We want to compose it with another natural transformation $\beta$ that goes from $G$ to $H$. Let's look at the components of these transformations at some object $X$
\[ \alpha_X \colon F \, X \to G \, X \]
\[ \beta_X \colon G \, X \to H \, X \]
These are just two arrows in $\mathcal{D}$ that are composable. So we can define a composite natural transformation $\gamma$ as follows:
\[ \gamma \colon F \to H\]
\[ \gamma_X = \beta_X \circ \alpha_X \]

Naturality condition for $\gamma$ can be shown by pasting together two naturality squares for $\alpha$ and $\beta$:
\[
 \begin{tikzcd}
 F X
 \arrow[d, "\alpha_X"]
 \arrow[r, "F f"]
 \arrow[dd, bend right = 60, "\gamma_X"']
 &
F Y
  \arrow[d, "\alpha_Y"]
 \arrow[dd, bend left = 60, "\gamma_Y"]
 \\
G X
 \arrow[r, "G f"]
 \arrow[d, "\beta_X"]
& G Y
\arrow[d, "\beta_Y"]
\\
H X
\arrow[r, "H f"]
& H Y
 \end{tikzcd}
\]

Since the composition of natural transformation is defined in terms of composition of arrows, it is automatically associative. There is also an identity natural transformation defined for every functor $F$, whose component at $X$ is the appropriate identity arrow:
\[ (id_F)_X = id_{F X} \]

To summarize, for every pair of categories $\mathcal{C}$ and $\mathcal{D}$ there is a category of functors $[\mathcal{C}, \mathcal{D}]$ with natural transformations as arrows. 

The hom-set in that category is the set of natural transformations between two functors $F$ and $G$. Following the standard notational convention, we write it as:
\[ [\mathcal{C}, \mathcal{D}](F, G) \]
with the name of the category followed by the names of the two objects (here, functors) in parentheses.

\begin{exercise}
Prove the naturality condition of the composition of natural transformations:
\[ \gamma_Y \circ F f = H f \circ \gamma_X \]
Hint: Use the definition of $\gamma$ and the two naturality conditions for $\alpha$ and $\beta$.
\end{exercise}



\section{Universal Constructions Revisited}

We've seen definitions of sums, products, exponentials, natural numbers, and lists. 

The traditional approach to defining such data types is to explore their internals. This is the set-theory way: we look at how the elements of new sets are constructed from the elements of old sets. An element of a sum is either an element of the first set, or the second set. An element of a product is a pair of elements. And so on. We are looking at objects from the engineering point of view.

In category theory we take the opposite approach. We are not interested in what's inside the object or how it's implemented. We are interested in the purpose of the object, how it can be used, and how it interacts with other objects. We are looking at objects from the user's point of view.

Both approaches have their advantages. The categorical approach came later, because you need to study a lot of examples before clear patterns emerge. But once you see the patterns, you discover unexpected connections between things: like the duality between sums and products.

Defining particular objects through their connection requires looking at possibly infinite numbers of objects. 

``Tell me your place in the Universe, and I'll tell you who you are.''

Defining an object by its mappings-out or mappings-in with respect to all objects in the category is called a \emph{universal construction}. 

Since most universal constructions involve commuting diagrams, they can often be reformulated at a higher level using natural transformations. We'll study one such example in great detail to get some understanding of the terse language of category theory. We'll try to decode the statement that the sum is defined by the following natural isomorphism:

\[ [\mathbf{2}, \mathcal{C}](D, \Delta_X]  \cong \mathcal{C}(A + B, X) \]

The important part of the process is to get familiar with some of the techniques used in category theory, especially the ability to mix different levels of abstraction. Being able to compress a lot of facts into small elegant formulas helps us see new patterns. We'll see, for instance, that natural isomorphisms between hom-sets pop up all over category theory and eventually lead us to the idea of an adjunction.

\subsection{Picking objects}

Even such a simple task as pointing at objects has a special meaning in category theory. We have already seen that, what used to be done by pointing to an element, was replaced by selecting an arrow from the terminal object. Similarly, picking an object in a category can be replaced by selecting a functor from a single-object category. Or it can be done by selecting a constant functor from some other category. 

We often want to select a pair of objects. That, too, can be accomplished by picking a functor from a two-object stick-figure category. Similarly, selecting an arrow is equivalent to picking a functor from the ``walking arrow'' category, and so on.

By judiciously picking our functors and natural transformations between them, we can reformulate all the universal constructions we've seen so far.

\subsection{Cospans as natural transformations}

The definition of a sum requires the selection of two objects to be summed, and a third object to serve as the target of the mapping out.

\[
 \begin{tikzcd}
 A
 \arrow[dr,  bend left, "\text{Left}"']
 \arrow[ddr, bend right, "f"']
 && B
 \arrow[dl, bend right, "\text{Right}"]
 \arrow[ddl, bend left, "g"]
 \\
&A + B
\arrow[d, dashed, "h"]
\\
& C
 \end{tikzcd}
\]
This diagram can be further decomposed into two simpler shapes called \emph{cospans}:
\[
 \begin{tikzcd}
 A
 \arrow[dr, "f"']
 && B
 \arrow[dl, "g"]
 \\
 & X
 \end{tikzcd}
\]

Since we want to select two objects, we'll start with a two-object category $\mathbf{2}$. We'll call its objects $1$ and $2$. 
We'll use a functor 
\[ D \colon \mathbf{2} \to \mathcal{C}\]
to select the objects $A$ and $B$: 
\[D\, 1 = A\]
\[ D\, 2 = B \]
($D$ stands for ``diagram'', since the two objects form a very simple diagram in $\mathcal{C}$.)

We'll use the constant functor 
\[ \Delta_X \colon \mathbf{2} \to \mathcal{C} \]
to select the object $X$. This functor maps both $1$ and $2$ to $X$.

Since both functors go from $\mathbf{2}$ to $\mathcal{C}$, we can define a natural transformation $\alpha$ between them. In this case, it's just a pair of arrows:
\[ \alpha_1 \colon D \, 1 \to \Delta_X 1 \]
\[ \alpha_2 \colon D \, 2 \to \Delta_X 2 \]
These are exactly the two arrows $f$ and $g$ in the diagram above. 

Naturality condition for $\alpha$ is trivial, since there are no arrows (other than identities) in $\mathbf{2}$.

There may be many cospans sharing the same three objects, meaning: there may be many natural transformations between the two functors $D$ and  $\Delta_X$. These natural transformations form a hom-set in the category of functors $[\mathbf{2}, \mathcal{C}]$, namely:
\[ [\mathbf{2}, \mathcal{C}](D, \Delta_X) \]

\subsection{Functoriality of cospans}

Let's consider what happens when we start varying the object $X$. We get a mapping from $X$ to the set of cospans:
\[ F X = [\mathbf{2}, \mathcal{C}](D, \Delta_X) \]
This mapping turns out to be functorial.

To see that, consider an arrow $f \colon X \to Y$. The lifting of this arrow would be a mapping between two sets of natural transformations:
\[ [\mathbf{2}, \mathcal{C}](D, \Delta_X) \to [\mathbf{2}, \mathcal{C}](D, \Delta_{Y}) \] 
 
This might look complicated until you remember that natural transformations have components, and these are just regular arrows. An element of the left-hand side is a natural transformation:
\[ \mu \colon D \to \Delta_X \]
It has two components corresponding to the two objects in $\mathbf{2}$. For instance, we have
\[ \mu_1 \colon D \, 1 \to \Delta_X 1 \]
or, using the definitions of $D$ and $\Delta$:
\[ \mu_1 \colon A \to X \]
This is just the function $f$ in the diagram. 

Similarly, the element of the right-hand side is:
\[ \nu \colon D \to \Delta_{Y} \]
Its component at $1$ is an arrow
\[ \nu_1 \colon A \to Y \]
We can get from $\mu_1$ to $\nu_1$ simply by post-composing it with $f$. So the lifting of $f$ is a component-by-component post-compositon $(f \circ -)$. 

A single post-composition can be applied to both components of $\mu$ because they both have the same target, $X$; and both components of $\nu$ have the same target $Y$.

\subsection{Sum as a universal cospan}

Of all the cospans that you can build on the pair $A$ and $B$, the one with the arrows we called $Left$ and $Right$ converging on $A + B$  is very special. There is a unique mapping out of it to any other cospan, that makes two triangles commute.  
\[
 \begin{tikzcd}
 A
 \arrow[dr,  bend left, "\text{Left}"']
 \arrow[ddr, bend right, "f"']
 && B
 \arrow[dl, bend right, "\text{Right}"]
 \arrow[ddl, bend left, "g"]
 \\
&A + B
\arrow[d, dashed, "h"]
\\
& X
 \end{tikzcd}
\]

We are now in a position to translate this condition into a statement about natural transformations and hom-sets. The arrow $h$ is an element of the hom-set 
\[ \mathcal{C}(A + B, X)\]
A cospan centered at $X$ is a natural transformation, that is an element of the hom-set in the functor category:
\[ [\mathbf{2}, \mathcal{C}](D, \Delta_X) \]

Both are hom-sets in their respective categories. But they are also sets, that is objects in the category $\mathbf{Set}$. This category forms a bridge between the functor category $[\mathbf{2}, \mathcal{C}]$ and a ``regular'' category $\mathcal{C}$, even though, conceptually, they seem to be at very different levels of abstraction. 

The universal construction is the isomorphism between these two sets:
\[ [\mathbf{2}, \mathcal{C}](D, \Delta_X)  \cong \mathcal{C}(A + B, X) \]

Moreover, if we vary the object $X$, the two sides behave like functors from  $\mathcal{C}$ to $\mathbf{Set}$. Therefore it makes sense to ask if this mapping of functors is a natural transformation. 

It turns out that the naturality condition for this isomorphism translates into commuting conditions for the triangles in the definition of the sum. So the definition of the sum can be replaced by a single equation.

\subsection{Product as a universal span}

The same argument can be made about the universal construction of the product. Again, we start with the stick-figure category $\mathbf{2}$ and the functor $D$. But this time we use a natural transformation going in the opposite direction
\[ \alpha \colon \Delta_X \to D \]
Such a natural transformation is a pair of arrows that form a \emph{span}:
\[
 \begin{tikzcd}
 &X
 \arrow[dl, "f"']
 \arrow[dr, "g"]
 \\
 A
 && B
  \end{tikzcd}
\]
Collectively, these natural transformations form a hom-set in the functor category :
\[[\mathbf{2}, \mathcal{C}](\Delta_X, D) \]

Every element of this hom-set is in one-to-one correspondence with a unique mapping $h$ into the product $A \times B$, which in turn is a member of the hom-set $\mathcal{C}(X, A \times B)$. This is expressed as an isomorphism:
\[ [\mathbf{2}, \mathcal{C}](\Delta_X, D)  \cong \mathcal{C}(X, A \times B) \]
The naturality of this isomorphism guarantees that the triangles in this diagram commute:
\[
 \begin{tikzcd}
 & C 
\arrow[d, dashed, "h"]
 \arrow[ddl, bend right, "f = \alpha_1"']
 \arrow[ddr, bend left, "g = \alpha_2"]
\\
&A \times B
 \arrow[dl,  "\text{fst}"]
  \arrow[dr,   "\text{snd}"']
\\
A = D\, 1 && B = D \, 2
 \end{tikzcd}
\]

\subsection{Exponentials}

The exponentials, or function objects, are defined by this commuting diagram:
\[
 \begin{tikzcd}
 X \times A
 \arrow[d, dashed, "h \times id_A"']
 \arrow[rd, "f"]
 \\
 B^A \times A
 \arrow[r, "\varepsilon"']
& B
 \end{tikzcd}
\]
Here, $f$ is an element of the hom-set $\mathcal{C}(X \times A, B)$ and $h$ is an element of $\mathcal{C}(X, B^A)$. We can use the natural isomorphism between these sets to define the exponential object. 
\[\mathcal{C}(X \times A, B) \cong \mathcal{C}(X, B^A)\]


\section{The Yoneda Lemma}

Yoneda embedding


\section{notes}

product/coproduct

mapping between models

composition (also, isomorphism as composition to identity NT)

2-category Cat

polymorphic functions

\begin{exercise}
\end{exercise}
\begin{haskell}
\end{haskell}
\[
 \begin{tikzcd}
  \end{tikzcd}
\]



\end{document}